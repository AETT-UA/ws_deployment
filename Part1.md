# Workshop de Deployment - Parte 1

DescriÃ§Ã£o do serviÃ§o a ser deployed:
* ServiÃ§o de marcaÃ§Ã£o de presenÃ§as em aulas;
* Interface HTML+JS+CSS 
* REST API em Django

## 1. Before anything else...

Correr a aplicaÃ§Ã£o em localhost e verificar se estÃ¡ tudo a funcionar corretamente.

Steps
``` bash
git clone https://github.com/AETT-UA/ws_deployment.git 
cd ws_deployment/base
./stop_on_ports.sh 8000 9000
./run.sh --rest-port 9000 --interface-port 8000
```
Ao correr o script run.sh, irÃ£o ser criados venvs com todos os packages necessÃ¡rio para correr a interface e a API. Posteriormente irÃ¡ ser usado um HTTP Simple Server para disponibilizar a interface e vai ser corrido o projeto Django.

ApÃ³s isto, podemos interagir com o serviÃ§o.

A interface grÃ¡fica estarÃ¡ disponÃ­vel em http://127.0.0.1:8000.
PS: Para nÃ£o acrescentar entropia ao workshop, sugere-se que seja utilizado Firefox.

Neste momento, devemos:

1. Registar um novo utilizador
2. Fazer login com o novo user
3. Criar uma folha de presenÃ§as
4. Registar 1 ou 2 alunos
5. Consultar registos de presenÃ§a
6. Fechar o registo de presenÃ§as
7. Logout

Podemos tambÃ©m ver a documentaÃ§Ã£o da API em: http://127.0.0.1:9000/documentation/ 

## 2. Correr a API REST utilizando o Gunircorn

**What is Gunicorn?**

[Gunicorn](https://gunicorn.org/) 'Green Unicorn' is a Python WSGI HTTP Server for UNIX. It's a pre-fork worker model. The Gunicorn server is broadly compatible with various web frameworks, simply implemented, light on server resources, and fairly speedy.

Steps:

### 2.1 Instalar o Gunicorn

 ``` bash
cd base/rest_api
source venv/bin/activate
python3 -m pip install gunicorn
``` 


### 2.2 Correr o projeto com o Gunicorn
		
``` bash
gunicorn --bind 0.0.0.0:9000 rest.wsgi:application --log-level debug
```

### 2.3 Correr Gunicorn com opÃ§Ãµes adiconais

OpÃ§Ãµes adicionais:
```
--workers -> The number of worker processes for handling requests
--max-requests  ->    The maximum number of requests a worker will process before restarting. 
```
 ConsideraÃ§Ãµes:
 ```
#workers <= num_cpu_multithread * 2
```
Run:
``` bash
gunicorn --bind 0.0.0.0:9000 --workers=4 --max-requests=500 rest.wsgi:application --log-level debug
```

ApÃ³s isto, devemos ter a API disponÃ­vel em http://127.0.0.1:9000/

### 2.4 O que acontece com static files?

Podem ir a http://127.0.0.1:9000/documentation e verificar que jÃ¡ nÃ£o tÃªm a interface do swagger.
Isto acontece porque o Gunicorn apenas irÃ¡ servvir conteÃºdo dinÃ¢mico e nÃ£o ficheiros estÃ¡ticos. Para servir este ficheiros estÃ¡ticos teremos posteriormente que usar um NGINX.


## 3. Correr a API REST em Production Mode

### 3.1 DEBUG Mode vs PRODUCTION Mode

Quando corremos projeto Django em DEBUG Mode, temos acesso a todos os logs de erros. Isto, em durante a fase de desenvolvimento, Ã© bastante Ãºtil, contudo, em produÃ§Ã£o nÃ£o queremos que os utilizadores seja capazes de ver como estÃ¡ o nosso cÃ³digo e quais as operaÃ§Ãµes que estamos a realizar. Em Production Mode, se existir algum erro, o utilizador apenas irÃ¡ saber que exisitu um erro, mas nÃ£o vai ter acesso ao StackTrace do mesmo. 

Quando corremos em modo DEBUG, o Django vai ser servido por um webserver python bastante simples. Este Ã© meramente um servidor de teste, sendo que, por exemplo, sÃ³ aguenta com 100 conexÃµes em simultÃ¢neo. Para alÃ©m disto, este webserver irÃ¡ disponibilizar ficheiros estÃ¡ticos, o que, em Production Mode, nÃ£o acontecerÃ¡.

Ao alterarmos para production mode temos de ter em atenÃ§Ã£o, por exemplo, a:

* BD que vamos usar
* Allowed Host
* CORS WhiteList
* etc...

### 3.2 Correr em Prod.

Para corrermos o projeto em produÃ§Ã£o temos de, em settings.py, alterar o valor da variÃ¡vel DEBUG para false.
Contudo, podemos querer alterar algumas configuraÃ§Ãµes com base no facto de estarmos em produÃ§Ã£o, ou nÃ£o. Por exemplo, a base de dados utilizada.

Assim, sugere-se a criaÃ§Ã£o de uma variÃ¡vel de ambiente que defina como pretendem correr o projeto.

``` python
# rest_api/rest/settings.py
RUNNING_MODE = os.environ.get("RUNNING_MODE", None)
PRODUCTION = RUNNING_MODE is  not  None  and RUNNING_MODE.lower() == 'production'
DEBUG = not PRODUCTION
```

Depois, podemos configurar o que pretendemos fazer em cada um dos modos:

``` python
# rest_api/rest/settings.py
if PRODUCTION:
	print("REST API running in production environment.")
	# Update configs as you wish
	ALLOWED_HOSTS = ['*']
	CORS_ALLOW_ALL_ORIGINS = True
	SECURE_SSL_REDIRECT = False
	# Database
	# ToDo
else:
	print("REST API running in development environment.")
	CORS_ALLOW_ALL_ORIGINS = True
	ALLOWED_HOSTS = ['*']
	SECURE_SSL_REDIRECT = False
	# Database
	DATABASES = {
	'default': {
		'ENGINE': 'django.db.backends.sqlite3',
		'NAME': os.path.join(BASE_DIR, 'db.sqlite3'),
		}
	}
```

Para testar, executar os seguintes comandos:
``` bash
export RUNNING_MODE=production
gunicorn --bind 0.0.0.0:9000 rest.wsgi:application --log-level debug
```

Reparem no que acontece quando vÃ£o a http://127.0.0.1:9000/ 


Vamos voltar a correr em DEBUG Mode:
``` bash
export RUNNING_MODE=debug
gunicorn --bind 0.0.0.0:9000 rest.wsgi:application --log-level debug
```

VÃ£o novamente a http://127.0.0.1:9000/ e vejam a diferenÃ§a ðŸ™‚

## 4. Base de Dados de ProduÃ§Ã£o

Para correr o projeto em produÃ§Ã£o vamos utilizar uma base de dados PostgreSQL.  Para tal, vamos lanÃ§ar um container com a mesma, ao nÃ­vel da VM que vos foi atribuÃ­da.

Para tal faÃ§am ssh para a vossa VM e executem os seguintes comandos:

``` bash
cd database
docker-compose up
```

Ao nÃ­vel do Dajngo Ã© necessÃ¡rio alterar a BD a ser utilizada:

``` python
if PRODUCTION:
	print("REST API running in production environment.")
	# Update configs as you wish
	ALLOWED_HOSTS = ['*']
	CORS_ALLOW_ALL_ORIGINS = True
	SECURE_SSL_REDIRECT = False
	
	# Database
	DATABASES = {
		'default': {
			'ENGINE': 'django.db.backends.postgresql_psycopg2',
			'NAME': 'postgres',
			'USER': 'postgres',
			'PASSWORD': 'postgres',
			'HOST': 'deti-engsoft-01.ua.pt', # change this
			'PORT': 5432,
		}
	}
```

Podem correr novamente o projeto com:
``` bash
export RUNNING_MODE=production
# just to be sure :)
./stop_on_ports.sh 8000 9000 
./run.sh --rest-port 9000 --interface-port 8000 
```


## 5. Imagens Docker

Vamos agora criar imagens docker de forma a empacotarmos a nossa aplicaÃ§Ã£o.
PS: As imagens docker que iremos criar sÃ£o MVPs, uma vez que o core deste workshop nÃ£o Ã© a utilizaÃ§Ã£o de Docker.

### 5.1 REST API

Temos de criar um Dockerfile, para contruir a imagem docker

``` bash
# na root
mkdir -p docker/api
```

Vamos agora criar o ficheiro `Dockerfile`, com o conteÃºdo:

``` dockerfile
FROM python:3
COPY rest_api/ /app
ADD docker/api/entrypoint.sh /app
RUN  apt update -y
WORKDIR /app
RUN pip3 install -r requirements.txt
RUN chmod +x entrypoint.sh
ENTRYPOINT ["./entrypoint.sh"]
```

No diretÃ³rio `docker/api` vamos criar  o ficheiro `entrypoint.sh` com o conteÃºdo:

``` bash
#!/bin/bash
python3 manage.py makemigrations api
python3 manage.py migrate
gunicorn --bind 0.0.0.0:9000 rest.wsgi:application --log-level debug
```

Podemos tambÃ©m iniciar jÃ¡ um docker-compose. Para tal, vamos criar o ficheiro `docker/docker-compose.yml`.

``` docker-compose
services:
	api:
		build:
			dockerfile: docker/api/Dockerfile
			context: ../
		ports:
		- 9000:9000
```

Neste momento podemos correr este docker compose (`docker-compose up`) e ir a http://127.0.0.1:9000 e verificar se a API estÃ¡ disponibilizada.

### 5.2 REST API - Extra

Ã‰ bastante Ãºtil podermos realizar algumas configuraÃ§Ãµes quando lanÃ§amos uma imagem docker. Ao nÃ­vel da REST API, por exemplo, podemos utilizar variÃ¡veis de ambiente, que serÃ£o definidas quando corremos o docker container. Podemos aplicar isto, por exemplo, Ã s configuraÃ§Ãµes da base de dados de produÃ§Ã£o.

Para tal, temos de editar o ficheiro `rest_api/rest/settings.py`.

``` python
DATABASES = {
	'default': {
		'ENGINE': 'django.db.backends.postgresql_psycopg2',
		'NAME': os.environ.get("DB_NAME", 'postgres'),
		'USER': os.environ.get("DB_USER", 'postgres'),
		'PASSWORD': os.environ.get("DB_PASSWORD", 'postgres'),
		'HOST': os.environ.get("DB_HOST", 'deti-engsoft-01.ua.pt'),
		'PORT': os.environ.get("DB_PORT", 5432),
	}
}
```

Temos agora que editar o nosso `docker-compose.yaml` de forma a definir estas variÃ¡veis de ambiente:

``` docker-compose
services:
	api:
		build:
			dockerfile: docker/api/Dockerfile
			context: ../
		ports:
			- 9000:9000
		environment:
			- RUNNING_MODE=production
			- DB_NAME=postgres
			- DB_USER=postgres
			- DB_PASSWORD=postgres
			- DB_HOST=deti-engsoft-01.ua.pt
			- DB_PORT=5432
```

### 5.3 Interface

Neste momento temos de servir a interface atravÃ©s de um webserver. Para tal vamos usar um NGINX.

Para tal, vamos alterar o nosso `docker-compose.yaml` para o seguinte:

``` docker-compose
services:
	nginx:
		image: nginx
		ports:
			- 8000:80
		volumes:
			- ../interface:/var/www/html/
			- ./interface/nginx.conf:/etc/nginx/nginx.conf
```

Posteriormente, temos de criar uma conf. para o NGINX. Criamos entÃ£o o ficheiro `docker/interface/nginx.conf`com o seguinte conteÃºdo:

``` nginx
events {
  worker_connections  1024;
}
http {
    include mime.types;
    server {
        listen 80;

        location / {
            root /var/www/html/;
            index index.html;
        }
    }
}
```

### 5.4 Interface + REST API + DB

Neste momento, vamos ter de alterar os url mapping da interface.
Para tal, vamos criar um ficheiro `docker/interface/urls.js` e injetÃ¡-lo atravÃ©s do docker-compose.

``` docker-compose
services:
	nginx:
		image: nginx
		ports:
			- 8000:80
		volumes:
			- ../interface:/var/www/html/
			- ./interface/nginx.conf:/etc/nginx/nginx.conf
			- ./interface/urls.js:/var/www/html/static/js/urls.js
```

O `docker-compose.yaml` deve ficar assim:

``` docker-compose
services:
    api:
        build:
            dockerfile: docker/api/Dockerfile
            context: ../
        ports:
            - 9000:9000
        environment:
            - RUNNING_MODE=production
            - DB_NAME=postgres
            - DB_USER=postgres    
            - DB_PASSWORD=postgres
            - DB_HOST=deti-engsoft-01.ua.pt
            - DB_PORT=5432

    nginx:
        image: nginx
        ports:
            - 8000:80
        volumes:
            -  ../interface:/var/www/html/
            - ./interface/nginx.conf:/etc/nginx/nginx.conf
            - ./interface/urls.js:/var/www/html/static/js/urls.js
```


Depois devemos editar o ficheiro `docker/inteface/urls.js` para o seguinte:

``` js
// API URLs
let  base_api = "http://localhost:8000/api";
let  base_url = "http://localhost:8000";
```

Neste momento temos de editar a NGINX conf. para fazer um proxypass do endpoint `/api`para a REST API. Para tal vamos ter de mapear o docker service atravÃ©s do seu name (api) :

``` nginx
events {
  worker_connections  1024;
}
http {
    include mime.types;
    server {
        listen 80;

        location / {
            root /var/www/html/;
            index index.html;
        }

        location /api/ {
            proxy_pass http://api:9000/;
        }
    }
}
```

Neste momento podemos adicionar a BD ao `docker-compose`. Geralmente, Ã© mÃ¡ polÃ­tica corrermos BDs em docker containers, contudo, para efeitos "educacionais" vamos fazÃª-lo.

Devemos, entÃ£o acicionar um container com a BD e alterar a variavÃ©l `DB_HOST`da `api` para apontar para este container.
Podemos, tambÃ©m, adcionar as tags `dependends_on`.

O docker-compose deve ficar assim:
``` docker-compose
services:
    db:
        image: postgres
        ports:
            - 5432:5432
        volumes:
            - ./data/db:/var/lib/postgresql/data
        environment:
            - POSTGRES_DB=postgres
            - POSTGRES_USER=postgres
            - POSTGRES_PASSWORD=postgres

    api:
        build:
            dockerfile: docker/api/Dockerfile
            context: ../
        ports:
            - 9000:9000
        environment:
            - RUNNING_MODE=production
            - DB_NAME=postgres
            - DB_USER=postgres    
            - DB_PASSWORD=postgres
            - DB_HOST=db
            - DB_PORT=5432
        depends_on:
            - "db"

    nginx:
        image: nginx
        ports:
            - 8000:80
        volumes:
            -  ../interface:/var/www/html/
            - ./interface/nginx.conf:/etc/nginx/nginx.conf
            - ./interface/urls.js:/var/www/html/static/js/urls.js
        depends_on:
            - "api"
```

Contudo, vamos ter alguns problemas a resolver. Se a API se ligar primeiro que a BD, esta vai dar erro, uma vez que nÃ£o consegue conectar-se Ã  BD.

Para tal, vamos editar o entrypoint da API de forma a que esta espere pela BD ðŸ™‚.

Podemos instalar a cli do postgres ao nÃ­vel no container da REST API. Para tal, vamos editar o ficheiro `docker/api/Dockerfile`para o seguinte:

``` dockerfile
FROM python:3
COPY rest_api/ /app
ADD docker/api/entrypoint.sh /app
RUN  apt update -y
RUN apt install postgresql postgresql-contrib -y
WORKDIR /app
RUN pip3 install -r requirements.txt
RUN chmod +x entrypoint.sh
ENTRYPOINT ["./entrypoint.sh"]
```

Vamos entÃ£o alterar o entrypoint (`docker/api/entrypoint.sh`) de forma a esperarmos pela BD:

```  bash
#!/bin/bash

RETRIES=40

until PGPASSWORD=$DB_PASSWORD psql -h $DB_HOST -U $DB_USER -p $DB_PORT -d $DB_NAME -c "select 1" > /dev/null 2>&1 || [ $RETRIES -eq 0 ]; do
  echo "Waiting for postgres server, $((RETRIES--)) remaining attempts..."
  sleep 5
done

echo "Connected to database!."

python3 manage.py makemigrations api
python3 manage.py migrate
gunicorn --bind 0.0.0.0:9000 rest.wsgi:application
--log-level debug
```

ApÃ³s isto, podemos verificar se estÃ¡ tudo funcional:
``` bash
cd docker 
docker-compose build
docker-compose up
```

## 6. Escalabilidade e Load Balancing

Se contruirmos uma REST API stateless, podemos facilmente replicÃ¡-la de forma a aumentarmos a quantidade de clientes suportados pelo sistema. Neste workshop vamos simular a escalabilidade da REST API atravÃ©s do deployment de 2 instÃ¢ncias da REST API.
Posteriormente, vamos utilizar o NGINX para distribuir a carga entre estas 2 rÃ©plicas. Isto tem apenas um propÃ³sito educacional, uma vez que hÃ¡ melhores formas de fazer auto-scaling da nossa aplicaÃ§Ã£o. Contudo, uma vez que estamos limitados pela duraÃ§Ã£o do workshop, esta Ã© uma boa forma de explorarmos o load balancing do NGINX.

Desta forma, vamos editar o nosso docker-compose para o seguinte:

``` docker-compose
services:
    db:
        image: postgres
        ports:
            - 5432:5432
        volumes:
            - ./data/db:/var/lib/postgresql/data
        environment:
            - POSTGRES_DB=postgres
            - POSTGRES_USER=postgres
            - POSTGRES_PASSWORD=postgres

    api_1:
        build:
            dockerfile: docker/api/Dockerfile
            context: ../
        environment:
            - RUNNING_MODE=production
            - DB_NAME=postgres
            - DB_USER=postgres    
            - DB_PASSWORD=postgres
            - DB_HOST=db
            - DB_PORT=5432
        depends_on:
            - "db"
    
    api_2:
        build:
            dockerfile: docker/api/Dockerfile
            context: ../
        environment:
            - RUNNING_MODE=production
            - DB_NAME=postgres
            - DB_USER=postgres    
            - DB_PASSWORD=postgres
            - DB_HOST=db
            - DB_PORT=5432
        depends_on:
            - "db"


    nginx:
        image: nginx
        ports:
            - 8000:80
        volumes:
            -  ../interface:/var/www/html/
            - ./interface/nginx.conf:/etc/nginx/nginx.conf
            - ./interface/urls.js:/var/www/html/static/js/urls.js
        depends_on:
            - "api_1"
            - "api_2"
```

Vamos tambÃ©m, ter que configurar o nosso NGINX para fazer load balancing:

``` nginx
events {
  worker_connections  1024;
}
http {
    upstream api {
        server api_1:9000;
        server api_2:9000;
    }
    include mime.types;
    server {
        listen 80;

        location / {
            root /var/www/html/;
            index index.html;
        }

        location /api/ {
            proxy_pass http://api/;
        }
    }
}
```


Depois:

``` bash
docker ps
docker logs <id_container_api_1>
docker logs <id_container_api_2>
``` 
Para verificarmos que existe um balancemanto de carga devemos registar um novo utilizador e realizar algumas operaÃ§Ãµes.

### Notes

Quem tiver problemas em instalar o `psycopg2` em Mac, pode executar este comando `export LIBRARY_PATH=$LIBRARY_PATH:/usr/local/opt/openssl/lib/`. This should do it.

### Filepaths:

```
â”œâ”€â”€ docker
â”‚Â Â  â”œâ”€â”€ api
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ Dockerfile
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ entrypoint.sh
â”‚Â Â  â”‚Â Â  â””â”€â”€ telegraf.conf
â”‚Â Â  â”œâ”€â”€ docker-compose.yaml
â”‚Â Â  â””â”€â”€ interface
â”‚Â Â   Â Â  â”œâ”€â”€ nginx.conf
â”‚Â Â   Â Â  â””â”€â”€ urls.js
â”‚Â Â        
â”œâ”€â”€ interface
â”‚Â Â  â””â”€â”€ ...
|
â”œâ”€â”€ rest_api
â”‚Â Â  â””â”€â”€ ...
|
â”œâ”€â”€ run.sh
â””â”€â”€ stop_on_ports.sh
```
