# Workshop de Deployment - Parte 1

Descri√ß√£o do servi√ßo a ser deployed:
* Servi√ßo de marca√ß√£o de presen√ßas em aulas;
* Interface HTML+JS+CSS 
* REST API em Django

## 1. Before anything else...

Correr a aplica√ß√£o em localhost e verificar se est√° tudo a funcionar corretamente.

Steps
``` bash
git clone https://github.com/AETT-UA/ws_deployment.git 
cd ws_deployment/base
./stop_on_ports.sh 8000 9000
./run.sh --rest-port 9000 --interface-port 8000
```
Ao correr o script run.sh, ir√£o ser criados venvs com todos os packages necess√°rio para correr a interface e a API. Posteriormente ir√° ser usado um HTTP Simple Server para disponibilizar a interface e vai ser corrido o projeto Django.

Ap√≥s isto, podemos interagir com o servi√ßo.

A interface gr√°fica estar√° dispon√≠vel em http://127.0.0.1:8000.
PS: Para n√£o acrescentar entropia ao workshop, sugere-se que seja utilizado Firefox.

Neste momento, devemos:

1. Registar um novo utilizador
2. Fazer login com o novo user
3. Criar uma folha de presen√ßas
4. Registar 1 ou 2 alunos
5. Consultar registos de presen√ßa
6. Fechar o registo de presen√ßas
7. Logout

Podemos tamb√©m ver a documenta√ß√£o da API em: http://127.0.0.1:9000/documentation/ 

## 2. Correr a API REST utilizando o Gunircorn

**What is Gunicorn?**

[Gunicorn](https://gunicorn.org/) 'Green Unicorn' is a Python WSGI HTTP Server for UNIX. It's a pre-fork worker model. The Gunicorn server is broadly compatible with various web frameworks, simply implemented, light on server resources, and fairly speedy.

Steps:

### 2.1 Instalar o Gunicorn

 ``` bash
cd base/rest_api
source venv/bin/activate
python3 -m pip install gunicorn
``` 


### 2.2 Correr o projeto com o Gunicorn
		
``` bash
gunicorn --bind 0.0.0.0:9000 rest.wsgi:application --log-level debug
```

### 2.3 Correr Gunicorn com op√ß√µes adiconais

Op√ß√µes adicionais:
```
--workers -> The number of worker processes for handling requests
--max-requests  ->    The maximum number of requests a worker will process before restarting. 
```
 Considera√ß√µes:
 ```
#workers <= num_cpu_multithread * 2
```
Run:
``` bash
gunicorn --bind 0.0.0.0:9000 --workers=4 --max-requests=500 rest.wsgi:application --log-level debug
```

Ap√≥s isto, devemos ter a API dispon√≠vel em http://127.0.0.1:9000/

### 2.4 O que acontece com static files?

Podem ir a http://127.0.0.1:9000/documentation e verificar que j√° n√£o t√™m a interface do swagger.
Isto acontece porque o Gunicorn apenas ir√° servvir conte√∫do din√¢mico e n√£o ficheiros est√°ticos. Para servir este ficheiros est√°ticos teremos posteriormente que usar um NGINX.


## 3. Correr a API REST em Production Mode

### 3.1 DEBUG Mode vs PRODUCTION Mode

Quando corremos projeto Django em DEBUG Mode, temos acesso a todos os logs de erros. Isto, em durante a fase de desenvolvimento, √© bastante √∫til, contudo, em produ√ß√£o n√£o queremos que os utilizadores seja capazes de ver como est√° o nosso c√≥digo e quais as opera√ß√µes que estamos a realizar. Em Production Mode, se existir algum erro, o utilizador apenas ir√° saber que exisitu um erro, mas n√£o vai ter acesso ao StackTrace do mesmo. 

Quando corremos em modo DEBUG, o Django vai ser servido por um webserver python bastante simples. Este √© meramente um servidor de teste, sendo que, por exemplo, s√≥ aguenta com 100 conex√µes em simult√¢neo. Para al√©m disto, este webserver ir√° disponibilizar ficheiros est√°ticos, o que, em Production Mode, n√£o acontecer√°.

Ao alterarmos para production mode temos de ter em aten√ß√£o, por exemplo, a:

* BD que vamos usar
* Allowed Host
* CORS WhiteList
* etc...

### 3.2 Correr em Prod.

Para corrermos o projeto em produ√ß√£o temos de, em settings.py, alterar o valor da vari√°vel DEBUG para false.
Contudo, podemos querer alterar algumas configura√ß√µes com base no facto de estarmos em produ√ß√£o, ou n√£o. Por exemplo, a base de dados utilizada.

Assim, sugere-se a cria√ß√£o de uma vari√°vel de ambiente que defina como pretendem correr o projeto.

``` python
# rest_api/rest/settings.py
RUNNING_MODE = os.environ.get("RUNNING_MODE", None)
PRODUCTION = RUNNING_MODE is  not  None  and RUNNING_MODE.lower() == 'production'
DEBUG = not PRODUCTION
```

Depois, podemos configurar o que pretendemos fazer em cada um dos modos:

``` python
# rest_api/rest/settings.py
if PRODUCTION:
	print("REST API running in production environment.")
	# Update configs as you wish
	ALLOWED_HOSTS = ['*']
	ORS_ALLOW_ALL_ORIGINS = True
	SECURE_SSL_REDIRECT = False
	# Database
	# ToDo
else:
	print("REST API running in development environment.")
	CORS_ALLOW_ALL_ORIGINS = True
	ALLOWED_HOSTS = ['*']
	SECURE_SSL_REDIRECT = False
	# Database
	DATABASES = {
	'default': {
		'ENGINE': 'django.db.backends.sqlite3',
		'NAME': os.path.join(BASE_DIR, 'db.sqlite3'),
		}
	}
```

Para testar, executar os seguintes comandos:
``` bash
export RUNNING_MODE=production
gunicorn --bind 0.0.0.0:9000 rest.wsgi:application --log-level debug
```

Reparem no que acontece quando v√£o a http://127.0.0.1:9000/ 


Vamos voltar a correr em DEBUG Mode:
``` bash
export RUNNING_MODE=debug
gunicorn --bind 0.0.0.0:9000 rest.wsgi:application --log-level debug
```

V√£o novamente a http://127.0.0.1:9000/ e vejam a diferen√ßa üôÇ

## 4. Base de Dados de Produ√ß√£o

Para correr o projeto em produ√ß√£o vamos utilizar uma base de dados PostgreSQL.  Para tal, vamos lan√ßar um container com a mesma, ao n√≠vel da VM que vos foi atribu√≠da.

Para tal fa√ßam ssh para a vossa VM e executem os seguintes comandos:

``` bash
cd database
docker-compose up
```

Ao n√≠vel do Dajngo √© necess√°rio alterar a BD a ser utilizada:

``` python
if PRODUCTION:
	print("REST API running in production environment.")
	# Update configs as you wish
	ALLOWED_HOSTS = ['*']
	CORS_ALLOW_ALL_ORIGINS = True
	SECURE_SSL_REDIRECT = False
	
	# Database
	DATABASES = {
		'default': {
			'ENGINE': 'django.db.backends.postgresql_psycopg2',
			'NAME': 'postgres',
			'USER': 'postgres',
			'PASSWORD': 'postgres',
			'HOST': 'deti-engsoft-01.ua.pt', # change this
			'PORT': 5432,
		}
	}
```

Podem correr novamente o projeto com:
``` bash
export RUNNING_MODE=production
# just to be sure :)
./stop_on_ports.sh 8000 9000 
./run.sh --rest-port 9000 --interface-port 8000 
```


## 5. Imagens Docker

Vamos agora criar imagens docker de forma a empacotarmos a nossa aplica√ß√£o.
PS: As imagens docker que iremos criar s√£o MVPs, uma vez que o core deste workshop n√£o √© a utiliza√ß√£o de Docker.

### 5.1 REST API

Temos de criar um Dockerfile, para contruir a imagem docker

``` bash
# na root
mkdir -p docker/api
```

Vamos agora criar o ficheiro `Dockerfile`, com o conte√∫do:

``` dockerfile
FROM python:3
COPY rest_api/ /app
ADD docker/api/entrypoint.sh /app
RUN  apt update -y
RUN apt install postgresql postgresql-contrib -y
WORKDIR /app
RUN pip3 install -r requirements.txt
RUN chmod +x entrypoint.sh
ENTRYPOINT ["./entrypoint.sh"]
```

No diret√≥rio `docker/api` vamos criar  o ficheiro `entrypoint.sh` com o conte√∫do:

``` bash
#!/bin/bash
python3 manage.py makemigrations api
python3 manage.py migrate
gunicorn --bind 0.0.0.0:9000 rest.wsgi:application --log-level debug
```

Podemos tamb√©m iniciar j√° um docker-compose. Para tal, vamos criar o ficheiro `docker/docker-compose.yml`.

``` docker-compose
services:
	api:
		build:
			dockerfile: docker/api/Dockerfile
			context: ../
		ports:
		- 9000:9000
```

Neste momento podemos correr este docker compose (`docker-compose up`) e ir a http://127.0.0.1:9000 e verificar se a API est√° disponibilizada.

### 5.2 REST API - Extra

√â bastante √∫til podermos realizar algumas configura√ß√µes quando lan√ßamos uma imagem docker. Ao n√≠vel da REST API, por exemplo, podemos utilizar vari√°veis de ambiente, que ser√£o definidas quando corremos o docker container. Podemos aplicar isto, por exemplo, √†s configura√ß√µes da base de dados de produ√ß√£o.

Para tal, temos de editar o ficheiro `rest_api/rest/settings.py`.

``` python
DATABASES = {
	'default': {
		'ENGINE': 'django.db.backends.postgresql_psycopg2',
		'NAME': os.environ.get("DB_NAME", 'postgres'),
		'USER': os.environ.get("DB_USER", 'postgres'),
		'PASSWORD': os.environ.get("DB_PASSWORD", 'postgres'),
		'HOST': os.environ.get("DB_HOST", 'deti-engsoft-01.ua.pt'),
		'PORT': os.environ.get("DB_PORT", 5432),
	}
}
```

Temos agora que editar o nosso `docker-compose.yaml` de forma a definir estas vari√°veis de ambiente:

``` docker-compose
services:
	api:
		build:
			dockerfile: docker/api/Dockerfile
			context: ../
		ports:
			- 9000:9000
		environment:
			- RUNNING_MODE=production
			- DB_NAME=postgres
			- DB_USER=postgres
			- DB_PASSWORD=postgres
			- DB_HOST=deti-engsoft-01.ua.pt
			- DB_PORT=5432
```

### 5.3 Interface

Neste momento temos de servir a interface atrav√©s de um webserver. Para tal vamos usar um NGINX.

Para tal, vamos alterar o nosso `docker-compose.yaml` para o seguinte:

``` docker-compose
services:
	nginx:
		image: nginx
		ports:
			- 8000:80
		volumes:
			- ../interface:/var/www/html/
			- ./interface/nginx.conf:/etc/nginx/nginx.conf
```

Posteriormente, temos de criar uma conf. para o NGINX. Criamos ent√£o o ficheiro `docker/interface/nginx.conf`com o seguinte conte√∫do:

``` nginx
events {
  worker_connections  1024;
}
http {
    include mime.types;
    server {
        listen 80;

        location / {
            root /var/www/html/;
            index index.html;
        }
    }
}
```

### 5.4 Interface + REST API + DB

Neste momento, vamos ter de alterar os url mapping da interface.
Para tal, vamos criar um ficheiro `docker/interface/urls.js` e injet√°-lo atrav√©s do docker-compose.

``` docker-compose
services:
	nginx:
		image: nginx
		ports:
			- 8000:80
		volumes:
			- ../interface:/var/www/html/
			- ./interface/nginx.conf:/etc/nginx/nginx.conf
			- ./interface/urls.js:/var/www/html/static/js/urls.js
```

O `docker-compose.yaml` deve ficar assim:

``` docker-compose
services:
    api:
        build:
            dockerfile: docker/api/Dockerfile
            context: ../
        ports:
            - 9000:9000
        environment:
            - RUNNING_MODE=production
            - DB_NAME=postgres
            - DB_USER=postgres    
            - DB_PASSWORD=postgres
            - DB_HOST=deti-engsoft-01.ua.pt
            - DB_PORT=5432

    nginx:
        image: nginx
        ports:
            - 8000:80
        volumes:
            -  ../interface:/var/www/html/
            - ./interface/nginx.conf:/etc/nginx/nginx.conf
            - ./interface/urls.js:/var/www/html/static/js/urls.js
```


Depois devemos editar o ficheiro `docker/inteface/urls.js` para o seguinte:

``` js
// API URLs
let  base_api = "http://localhost:8000/api";
let  base_url = "http://localhost:8000";
```

Neste momento temos de editar a NGINX conf. para fazer um proxypass do endpoint `/api`para a REST API. Para tal vamos ter de mapear o docker service atrav√©s do seu name (api) :

``` nginx
events {
  worker_connections  1024;
}
http {
    include mime.types;
    server {
        listen 80;

        location / {
            root /var/www/html/;
            index index.html;
        }

        location /api/ {
            proxy_pass http://api:9000/;
        }
    }
}
```

Neste momento podemos adicionar a BD ao `docker-compose`. Geralmente, √© m√° pol√≠tica corrermos BDs em docker containers, contudo, para efeitos "educacionais" vamos faz√™-lo.

Devemos, ent√£o acicionar um container com a BD e alterar a variav√©l `DB_HOST`da `api` para apontar para este container.
Podemos, tamb√©m, adcionar as tags `dependends_on`.

O docker-compose deve ficar assim:
``` docker-compose
services:
    db:
        image: postgres
        ports:
            - 5432:5432
        volumes:
            - ./data/db:/var/lib/postgresql/data
        environment:
            - POSTGRES_DB=postgres
            - POSTGRES_USER=postgres
            - POSTGRES_PASSWORD=postgres

    api:
        build:
            dockerfile: docker/api/Dockerfile
            context: ../
        ports:
            - 9000:9000
        environment:
            - RUNNING_MODE=production
            - DB_NAME=postgres
            - DB_USER=postgres    
            - DB_PASSWORD=postgres
            - DB_HOST=db
            - DB_PORT=5432
        depends_on:
            - "db"

    nginx:
        image: nginx
        ports:
            - 8000:80
        volumes:
            -  ../interface:/var/www/html/
            - ./interface/nginx.conf:/etc/nginx/nginx.conf
            - ./interface/urls.js:/var/www/html/static/js/urls.js
        depends_on:
            - "api"
```

Contudo, vamos ter alguns problemas a resolver. Se a API se ligar primeiro que a BD, esta vai dar erro, uma vez que n√£o consegue conectar-se √† BD.

Para tal, vamos editar o entrypoint da API de forma a que esta espere pela BD üôÇ.

Podemos instalar a cli do postgres ao n√≠vel no container da REST API. Para tal, vamos editar o ficheiro `docker/api/entrypoint.sh`para o seguinte:

``` dockerfile
FROM python:3
COPY . /app
RUN  apt update -y
RUN apt install postgresql postgresql-contrib -y
WORKDIR /app
RUN pip3 install -r requirements.txt
RUN chmod +x rest_api_starter.sh
ENTRYPOINT ["./entrypoint.sh"]
```

Vamos ent√£o alterar o entrypoint (`docker/api/entrypoint.sh`) de forma a esperarmos pela BD:

```  bash
#!/bin/bash

RETRIES=40

until PGPASSWORD=$DB_PASSWORD psql -h $DB_HOST -U $DB_USER -p $DB_PORT -d $DB_NAME -c "select 1" > /dev/null 2>&1 || [ $RETRIES -eq 0 ]; do
  echo "Waiting for postgres server, $((RETRIES--)) remaining attempts..."
  sleep 5
done

echo "Connected to database!."

python3 manage.py makemigrations api
python3 manage.py migrate
gunicorn --bind 0.0.0.0:9000 rest.wsgi:application
--log-level debug
```

Ap√≥s isto, podemos verificar se est√° tudo funcional:
``` bash
cd docker 
docker-compose build
docker-compose up
```


## 6. Caching

Vamos configurar os mecanismos de caching ao n√≠vel do NGINX. 
Neste caso, os nossos recursos v√£o ficar em cache durante 5 dias.

``` nginx
# cache
expires 5d;
add_header Cache-Control "public, no-transform";
```

De forma a reduzirmos a largura de banda utilizada, podemos tamb√©m servir os recursos de forma comprimida. Para tal, utilizaremos indicativas do gzip.

``` nginx
gzip on;
gzip_static on;
gzip_disable "msie6";
gzip_vary on;
gzip_proxied any;
gzip_comp_level 6;
gzip_buffers 16 8k;
gzip_http_version 1.1;
```

Temos de ter cuidado, contudo, uma vez que os algoritmos de compress√£o consomem CPU, quer do lado do servidor, quer do lado do cliente, que ir√° ter de fazer decompress dos ficheiros. Assim, temos de definir um n√≠vel de compress√£o atrav√©s de vari√°veis como `gzip_min_length`, `gzip_comp_level`, etc...

Podemos, ent√£o, altarar a nossa config NGINX para:

``` nginx
events {
  worker_connections  1024;
}
http {
    include mime.types;
    server {
        listen 80;

        location / {
            root /var/www/html/;
            index index.html;
            
            # gzip  
            gzip on;
            gzip_static on;
            gzip_disable "msie6";
            gzip_vary on;
            gzip_proxied any;
            gzip_comp_level 6;
            gzip_buffers 16 8k;
            gzip_http_version 1.1;
            gzip_types application/javascript application/rss+xml application/vnd.ms-fontobject application/x-font application/x-font-opentype application/x-font-otf application/x-font-truetype application/x-font-ttf application/x-javascript application/xhtml+xml application/xml font/opentype font/otf font/ttf image/svg+xml image/x-icon text/css text/javascript text/plain text/xml;
            
            # cache
            expires 5d;
            add_header Cache-Control "public, no-transform";        
        }

        location /api/ {
            proxy_pass http://api:9000/;
        }
    }
}
```

Ap√≥s isto, podemos verificar se est√° tudo funcional:
``` bash
docker-compose down
docker-compose down
```

A primeira vez que abrirem o nosso site, deve encontrar-se com uma network semelhante a esta:

![No cache](https://i.imgur.com/Vo6WwGG.png)

Contudo, na segunda vez que consultarem o site, os ficheiros j√° devem estar a ser servidos a partir da cache:

![With cache](https://imgur.com/s7dvYm6.png)


Tamb√©m podemos ver que os ficheiros foram zipados:

![gzip](https://imgur.com/0b9vEog.png)



## 7. Escalabilidade e Load Balancing

Se contruirmos uma REST API stateless, podemos facilmente replic√°-la de forma a aumentarmos a quantidade de clientes suportados pelo sistema. Neste workshop vamos simular a escalabilidade da REST API atrav√©s do deployment de 2 inst√¢ncias da REST API.
Posteriormente, vamos utilizar o NGINX para distribuir a carga entre estas 2 r√©plicas. Isto tem apenas um prop√≥sito educacional, uma vez que h√° melhores formas de fazer auto-scaling da nossa aplica√ß√£o. Contudo, uma vez que estamos limitados pela dura√ß√£o do workshop, esta √© uma boa forma de explorarmos o load balancing do NGINX.

Desta forma, vamos editar o nosso docker-compose para o seguinte:

``` docker-compose
services:
    db:
        image: postgres
        ports:
            - 5432:5432
        volumes:
            - ./data/db:/var/lib/postgresql/data
        environment:
            - POSTGRES_DB=postgres
            - POSTGRES_USER=postgres
            - POSTGRES_PASSWORD=postgres

    api_1:
        build:
            dockerfile: docker/api/Dockerfile
            context: ../
        environment:
            - RUNNING_MODE=production
            - DB_NAME=postgres
            - DB_USER=postgres    
            - DB_PASSWORD=postgres
            - DB_HOST=db
            - DB_PORT=5432
        depends_on:
            - "db"
    
    api_2:
        build:
            dockerfile: docker/api/Dockerfile
            context: ../
        environment:
            - RUNNING_MODE=production
            - DB_NAME=postgres
            - DB_USER=postgres    
            - DB_PASSWORD=postgres
            - DB_HOST=db
            - DB_PORT=5432
        depends_on:
            - "db"


    nginx:
        image: nginx
        ports:
            - 8000:80
        volumes:
            -  ../interface:/var/www/html/
            - ./interface/nginx.conf:/etc/nginx/nginx.conf
            - ./interface/urls.js:/var/www/html/static/js/urls.js
        depends_on:
            - "api_1"
            - "api_2"
```

Vamos tamb√©m, ter que configurar o nosso NGINX para fazer load balancing:

``` nginx
events {
  worker_connections  1024;
}
http {
    upstream api {
        server api_1:9000;
        server api_2:9000;
    }

    include mime.types;
    server {
        listen 80;

        location / {
            root /var/www/html/;
            index index.html;

            # gzip  
            gzip on;
            gzip_static on;
            gzip_disable "msie6";
            gzip_vary on;
            gzip_proxied any;
            gzip_comp_level 6;
            gzip_buffers 16 8k;
            gzip_http_version 1.1;
            gzip_types application/javascript application/rss+xml application/vnd.ms-fontobject application/x-font application/x-font-opentype application/x-font-otf application/x-font-truetype application/x-font-ttf application/x-javascript application/xhtml+xml application/xml font/opentype font/otf font/ttf image/svg+xml image/x-icon text/css text/javascript text/plain text/xml;
            
            # cache
            expires 5d;
            add_header Cache-Control "public, no-transform";
        }

        location /api/ {
            proxy_pass http://api/;
        }
    }
}```


Para verificarmos que existe um balancemanto de carga devemos registar um novo utilizador e realizar algumas opera√ß√µes.

Depois:

``` bash
docker ps
docker logs <id_container_api_1>
docker logs <id_container_api_2>
``` 

Devemos ver os seguintes logs:

![gzip](https://imgur.com/QstTWK9.png)


